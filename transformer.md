The Transformer was presented in paper [Attention Is All You Need](https://arxiv.org/abs/1706.03762).

## Scaled Dot-Product Attention
